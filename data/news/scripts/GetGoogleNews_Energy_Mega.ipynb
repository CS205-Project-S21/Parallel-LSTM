{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"../../../utils/\")\n",
    "from fetchgooglenews import GoogleNews\n",
    "from fetchcontextweb import fetch_context_web\n",
    "import datetime\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = datetime.date(2010,1,1)\n",
    "enddate = datetime.date(2016,3,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_periods(startdate, enddate, length=30, shift=-1):\n",
    "    totaldays = (enddate - startdate).days + 1\n",
    "    num_periods = math.ceil(totaldays/length)\n",
    "    output_dates = []\n",
    "    for i in range(0, num_periods):\n",
    "        if i < num_periods-1:\n",
    "            leftdate = startdate + datetime.timedelta(days=i*length)\n",
    "            rightdate = startdate + datetime.timedelta(days=((i+1)*length+shift))\n",
    "        else:\n",
    "            leftdate = startdate + datetime.timedelta(days=i*length)\n",
    "            rightdate = enddate\n",
    "        leftdate_str = datetime.date.strftime(leftdate, \"%m/%d/%Y\")\n",
    "        rightdate_str = datetime.date.strftime(rightdate, \"%m/%d/%Y\")\n",
    "        output_dates.append((leftdate_str, rightdate_str))\n",
    "    return output_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(keywords, time_periods, outname, MAX_PAGE=5, duplicate=True, pause=1):\n",
    "    # Download news by scrapping google search news section\n",
    "    results_all = []\n",
    "    count = 0\n",
    "    for leftdate, rightdate in time_periods:\n",
    "        # Duplicate will copy same article twice, and set one at 4am one at 12pm\n",
    "        googlenews = GoogleNews(lang='en', start=leftdate,end=rightdate, numperpage=50, duplicate=duplicate)\n",
    "        googlenews.search(keywords)\n",
    "        for i in range(2,MAX_PAGE+1):\n",
    "            time.sleep(pause)\n",
    "            googlenews.get_page(i)\n",
    "            if googlenews.failflag() == 1:\n",
    "                break\n",
    "        results_all.extend(googlenews.results())\n",
    "        print(\"Finish Request from {} to {}, Get {} articles\".format(leftdate, rightdate, len(googlenews.results())))\n",
    "        time.sleep(10)\n",
    "        count += 1\n",
    "        if count % 10 == 0:\n",
    "            pd.DataFrame(results_all).to_csv(outname.format(count//10))\n",
    "            print(\"Reach 10 requests capacity, will sleep for 2000s. Last batch has been saved as period {}\".format(count//10))\n",
    "            time.sleep(2000)\n",
    "    return results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_cw(keywords, time_periods, MAX_PAGE=5):\n",
    "    # Download news by scrapping google search news section\n",
    "    results_all = []\n",
    "    \n",
    "    for leftdate, rightdate in time_periods:\n",
    "        results_period = []\n",
    "        \n",
    "        for i in range(1,MAX_PAGE+1):\n",
    "            tmp_results, fail_flag = fetch_context_web(keywords, leftdate, rightdate, page=i)\n",
    "            results_period.extend(tmp_results)\n",
    "            if fail_flag == 1:\n",
    "                break\n",
    "        results_all.extend(results_period)\n",
    "        print(\"Finish Request from {} to {}, Get {} articles\".format(leftdate, rightdate, len(results_period)))\n",
    "    return results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeperiods = generate_periods(startdate, enddate, length=30, shift=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "Scrapping google search has some risks. **The best practice is downloading 10 timeperiods at one time with `get_news`, wait for about half an hour, do another 10 timeperiods.**\n",
    "\n",
    "At maximum, as I tried, we can keep downloading 14 timepriods, then the IP will be blocked for about 2 hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Energy news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'oil gas energy'\n",
    "output_file_name= \"../data/energy/GoogleNews_Energy_Mega_period_{}.csv\"\n",
    "MAX_PAGE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('02/29/2016', '03/29/2016')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeperiods[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Request from 01/01/2010 to 01/30/2010, Get 482 articles\n",
      "Finish Request from 01/31/2010 to 03/01/2010, Get 484 articles\n",
      "Finish Request from 03/02/2010 to 03/31/2010, Get 470 articles\n",
      "Finish Request from 04/01/2010 to 04/30/2010, Get 468 articles\n",
      "Finish Request from 05/01/2010 to 05/30/2010, Get 480 articles\n",
      "Finish Request from 05/31/2010 to 06/29/2010, Get 490 articles\n",
      "Finish Request from 06/30/2010 to 07/29/2010, Get 484 articles\n",
      "Finish Request from 07/30/2010 to 08/28/2010, Get 478 articles\n",
      "Finish Request from 08/29/2010 to 09/27/2010, Get 480 articles\n",
      "Finish Request from 09/28/2010 to 10/27/2010, Get 478 articles\n",
      "Reach 10 requests capacity, will sleep for 2000s. Last batch has been saved as period 1\n",
      "Finish Request from 10/28/2010 to 11/26/2010, Get 490 articles\n",
      "Finish Request from 11/27/2010 to 12/26/2010, Get 488 articles\n",
      "Finish Request from 12/27/2010 to 01/25/2011, Get 488 articles\n",
      "Finish Request from 01/26/2011 to 02/24/2011, Get 500 articles\n",
      "Finish Request from 02/25/2011 to 03/26/2011, Get 496 articles\n",
      "Finish Request from 03/27/2011 to 04/25/2011, Get 494 articles\n",
      "Finish Request from 04/26/2011 to 05/25/2011, Get 498 articles\n",
      "Finish Request from 05/26/2011 to 06/24/2011, Get 494 articles\n",
      "Finish Request from 06/25/2011 to 07/24/2011, Get 488 articles\n",
      "Finish Request from 07/25/2011 to 08/23/2011, Get 492 articles\n",
      "Reach 10 requests capacity, will sleep for 2000s. Last batch has been saved as period 2\n",
      "Finish Request from 08/24/2011 to 09/22/2011, Get 496 articles\n",
      "Finish Request from 09/23/2011 to 10/22/2011, Get 500 articles\n",
      "Finish Request from 10/23/2011 to 11/21/2011, Get 500 articles\n",
      "Finish Request from 11/22/2011 to 12/21/2011, Get 494 articles\n",
      "Finish Request from 12/22/2011 to 01/20/2012, Get 500 articles\n",
      "Finish Request from 01/21/2012 to 02/19/2012, Get 498 articles\n",
      "Finish Request from 02/20/2012 to 03/20/2012, Get 500 articles\n",
      "Finish Request from 03/21/2012 to 04/19/2012, Get 488 articles\n",
      "Finish Request from 04/20/2012 to 05/19/2012, Get 490 articles\n",
      "Finish Request from 05/20/2012 to 06/18/2012, Get 500 articles\n",
      "Reach 10 requests capacity, will sleep for 2000s. Last batch has been saved as period 3\n",
      "Finish Request from 06/19/2012 to 07/18/2012, Get 498 articles\n",
      "Finish Request from 07/19/2012 to 08/17/2012, Get 496 articles\n",
      "Finish Request from 08/18/2012 to 09/16/2012, Get 488 articles\n",
      "Finish Request from 09/17/2012 to 10/16/2012, Get 498 articles\n",
      "Finish Request from 10/17/2012 to 11/15/2012, Get 496 articles\n",
      "Finish Request from 11/16/2012 to 12/15/2012, Get 492 articles\n",
      "Finish Request from 12/16/2012 to 01/14/2013, Get 492 articles\n",
      "Finish Request from 01/15/2013 to 02/13/2013, Get 496 articles\n",
      "Finish Request from 02/14/2013 to 03/15/2013, Get 490 articles\n",
      "Finish Request from 03/16/2013 to 04/14/2013, Get 490 articles\n",
      "Reach 10 requests capacity, will sleep for 2000s. Last batch has been saved as period 4\n",
      "Finish Request from 04/15/2013 to 05/14/2013, Get 494 articles\n",
      "Finish Request from 05/15/2013 to 06/13/2013, Get 500 articles\n",
      "Finish Request from 06/14/2013 to 07/13/2013, Get 494 articles\n",
      "Finish Request from 07/14/2013 to 08/12/2013, Get 496 articles\n",
      "Finish Request from 08/13/2013 to 09/11/2013, Get 494 articles\n",
      "Finish Request from 09/12/2013 to 10/11/2013, Get 498 articles\n",
      "Finish Request from 10/12/2013 to 11/10/2013, Get 492 articles\n",
      "Finish Request from 11/11/2013 to 12/10/2013, Get 498 articles\n",
      "Finish Request from 12/11/2013 to 01/09/2014, Get 496 articles\n",
      "Finish Request from 01/10/2014 to 02/08/2014, Get 496 articles\n",
      "Reach 10 requests capacity, will sleep for 2000s. Last batch has been saved as period 5\n",
      "Finish Request from 02/09/2014 to 03/10/2014, Get 494 articles\n",
      "Finish Request from 03/11/2014 to 04/09/2014, Get 496 articles\n",
      "Finish Request from 04/10/2014 to 05/09/2014, Get 492 articles\n",
      "Finish Request from 05/10/2014 to 06/08/2014, Get 490 articles\n",
      "Finish Request from 06/09/2014 to 07/08/2014, Get 490 articles\n",
      "Finish Request from 07/09/2014 to 08/07/2014, Get 498 articles\n",
      "Finish Request from 08/08/2014 to 09/06/2014, Get 494 articles\n",
      "Finish Request from 09/07/2014 to 10/06/2014, Get 480 articles\n",
      "Finish Request from 10/07/2014 to 11/05/2014, Get 500 articles\n",
      "Finish Request from 11/06/2014 to 12/05/2014, Get 426 articles\n",
      "Reach 10 requests capacity, will sleep for 2000s. Last batch has been saved as period 6\n",
      "Finish Request from 12/06/2014 to 01/04/2015, Get 490 articles\n",
      "Finish Request from 01/05/2015 to 02/03/2015, Get 446 articles\n",
      "Finish Request from 02/04/2015 to 03/05/2015, Get 488 articles\n",
      "Finish Request from 03/06/2015 to 04/04/2015, Get 494 articles\n",
      "Finish Request from 04/05/2015 to 05/04/2015, Get 500 articles\n",
      "Finish Request from 05/05/2015 to 06/03/2015, Get 496 articles\n",
      "Finish Request from 06/04/2015 to 07/03/2015, Get 494 articles\n",
      "Finish Request from 07/04/2015 to 08/02/2015, Get 498 articles\n",
      "Finish Request from 08/03/2015 to 09/01/2015, Get 498 articles\n",
      "Finish Request from 09/02/2015 to 10/01/2015, Get 492 articles\n",
      "Reach 10 requests capacity, will sleep for 2000s. Last batch has been saved as period 7\n",
      "Finish Request from 10/02/2015 to 10/31/2015, Get 488 articles\n",
      "Finish Request from 11/01/2015 to 11/30/2015, Get 496 articles\n",
      "Finish Request from 12/01/2015 to 12/30/2015, Get 492 articles\n",
      "Finish Request from 12/31/2015 to 01/29/2016, Get 462 articles\n",
      "Finish Request from 01/30/2016 to 02/28/2016, Get 496 articles\n",
      "Finish Request from 02/29/2016 to 03/29/2016, Get 488 articles\n",
      "'NoneType' object is not iterable\n",
      "Finish Request from 03/30/2016 to 03/30/2016, Get 62 articles\n"
     ]
    }
   ],
   "source": [
    "Energy_news = get_news(keyword,timeperiods, outname=output_file_name, MAX_PAGE=MAX_PAGE, duplicate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(Energy_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37322"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-03-30 12:00:00')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.datetime.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"../data/energy/GoogleNews_Energy_Mega_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = datetime.date(2009,1,1)\n",
    "enddate = datetime.date(2009,10,27)\n",
    "timeperiods = generate_periods(startdate, enddate, length=30, shift=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Energy_news2 = get_news(keyword,timeperiods, outname=output_file_name, MAX_PAGE=MAX_PAGE, duplicate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = datetime.date(2009,10,28)\n",
    "enddate = datetime.date(2009,12,31)\n",
    "timeperiods = generate_periods(startdate, enddate, length=30, shift=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_news3 = get_news(keyword,timeperiods, outname=output_file_name, MAX_PAGE=MAX_PAGE, duplicate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the news from different sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/energy/GoogleNews_Energy_large_all.csv')\n",
    "df2 = pd.read_csv('../data/energy/GoogleNews_Energy_Mega_1.csv', index_col=0)\n",
    "df3 = pd.read_csv('../data/energy/GoogleNews_Energy_Mega_2.csv', index_col=0)\n",
    "df4 = pd.read_csv('../data/energy/GoogleNews_Energy_Mega_3.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateframe_all = pd.concat([df1,df2,df3,df4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateframe_all.sort_values(by=['datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateframe_test = dateframe_all.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009-01-01 04:00:00'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateframe_test.datetime.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-04-16 23:28:49'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateframe_test.datetime.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateframe_test.to_csv(\"../data/energy/GoogleNews_Energy_Mega_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spider",
   "language": "python",
   "name": "spider"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
