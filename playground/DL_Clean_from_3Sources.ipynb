{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAPID_API_KEY = '67f58679fcmsh1d5d86c70be0778p1320e2jsn414d9154fae0'\n",
    "NEWS_API_KEY = '7b294a567b694de5b23397387713d7f6' \n",
    "\n",
    "keyword = \"Bitcoin\"\n",
    "ticker = \"TSLA\" \n",
    "startdate = \"2021-04-15T00:00:00\"\n",
    "enddate = \"2021-04-15T23:59:59\"\n",
    "output_file_name= r\"../data/news_larger.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structure for final output\n",
    "news = {'source': [], 'author': [], 'time': [], 'title': [],\n",
    "        'description': [], 'content': [], 'url': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Contextual Web Search API, 100 Request per day, 100 articles every time\n",
    "url1 = \"https://contextualwebsearch-websearch-v1.p.rapidapi.com/api/search/NewsSearchAPI\"\n",
    "querystring1 = {\"q\":keyword,\"pageNumber\":\"1\",\"pageSize\":\"50\",\"autoCorrect\":\"true\",\"fromPublishedDate\":startdate,\n",
    "               \"toPublishedDate\":enddate}\n",
    "headers1 = {\n",
    "    'x-rapidapi-key': RAPID_API_KEY,\n",
    "    'x-rapidapi-host': \"contextualwebsearch-websearch-v1.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "response1 = requests.request(\"GET\", url1, headers=headers1, params=querystring1)\n",
    "\n",
    "try: \n",
    "    body1 = json.loads(response1.text)\n",
    "    articles1 = body1[\"value\"]\n",
    "    n_articles = len(articles1)\n",
    "\n",
    "    for i, article in enumerate(articles1):\n",
    "        news['source'].append(article['provider']['name'])\n",
    "        news['author'].append(\"NotProvided\")\n",
    "        news['time'].append(article['datePublished'])\n",
    "        news['title'].append(article['title'])\n",
    "        news['description'].append(re.sub(r'(\\r|\\n|<.*?>|…)+', ' ', article['description']).strip())\n",
    "        news['content'].append(re.sub(r'(\\r|\\n|<.*?>|… \\[\\+[0-9]+ chars])+', ' ', article['body']).strip())\n",
    "        news['url'].append(article['url'])\n",
    "except:\n",
    "    warnings.warn(\"Fail to get news from Contextual Web Search API!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url21 = \"https://newscatcher.p.rapidapi.com/v1/stocks\"\n",
    "querystring21 = {\"ticker\":ticker,\"from\":startdate,\"to\":enddate,\"lang\":\"en\",\"stock\":\"NASDAQ\",\"media\":\"True\",\"sort_by\":\"relevancy\"}\n",
    "\n",
    "headers21 = {\n",
    "    'x-rapidapi-key': RAPID_API_KEY,\n",
    "    'x-rapidapi-host': \"newscatcher.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "response21 = requests.request(\"GET\", url21, headers=headers21, params=querystring21)\n",
    "\n",
    "try: \n",
    "    body21 = json.loads(response21.text)\n",
    "    articles21 = body21[\"articles\"]\n",
    "    n_articles21 = len(articles21)\n",
    "\n",
    "    for i, article in enumerate(articles21):\n",
    "        news['source'].append(\"NotProvided\")\n",
    "        news['author'].append(re.sub(r'(\\r|\\n|<.*?>|…)+', ' ', str(article['author'])).strip())\n",
    "        news['time'].append(article['published_date'])\n",
    "        news['title'].append(article['title'])\n",
    "        news['description'].append(re.sub(r'(\\r|\\n|<.*?>|…)+', ' ', article['summary']).strip())\n",
    "        news['content'].append(\"NotProvided\")\n",
    "        news['url'].append(article['link'])\n",
    "except:\n",
    "    warnings.warn(\"Fail to get news from Newscatcher API Stock Search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url22 = \"https://newscatcher.p.rapidapi.com/v1/search\"\n",
    "querystring22 = {\"q\":keyword,\"from\":startdate,\"to\":enddate,\"lang\":\"en\",\"media\":\"True\",\"sort_by\":\"relevancy\"}\n",
    "\n",
    "headers22 = {\n",
    "    'x-rapidapi-key': RAPID_API_KEY,\n",
    "    'x-rapidapi-host': \"newscatcher.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "response22 = requests.request(\"GET\", url22, headers=headers22, params=querystring22)\n",
    "\n",
    "try: \n",
    "    body22 = json.loads(response22.text)\n",
    "    articles22 = body22[\"articles\"]\n",
    "    n_articles22 = len(articles22)\n",
    "\n",
    "    for i, article in enumerate(articles22):\n",
    "        news['source'].append(\"NotProvided\")\n",
    "        news['author'].append(re.sub(r'(\\r|\\n|<.*?>|…)+', ' ', str(article['author'])).strip())\n",
    "        news['time'].append(article['published_date'])\n",
    "        news['title'].append(article['title'])\n",
    "        news['description'].append(re.sub(r'(\\r|\\n|<.*?>|…)+', ' ', article['summary']).strip())\n",
    "        news['content'].append(\"NotProvided\")\n",
    "        news['url'].append(article['link'])\n",
    "except:\n",
    "    warnings.warn(\"Fail to get news from Newscatcher API Keyword Search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = ('https://newsapi.org/v2/everything?'\n",
    "       'q='+keyword+'&'\n",
    "       'from='+startdate+'&'\n",
    "       'to='+enddate+'&'\n",
    "       'sortBy=relevancy&'\n",
    "       'pageSize=100&'\n",
    "       'apiKey='+NEWS_API_KEY)\n",
    "\n",
    "try: \n",
    "    articles3 = requests.get(url3).json()['articles']\n",
    "\n",
    "    for i, article in enumerate(articles3):\n",
    "        news['source'].append(article['source']['name'])\n",
    "        news['author'].append(re.sub(r'(\\r|\\n|<.*?>|…)+', ' ', str(article['author'])).strip())\n",
    "        news['time'].append(article['publishedAt'])\n",
    "        news['title'].append(article['title'])\n",
    "        news['description'].append(re.sub(r'(\\r|\\n|<.*?>|…)+', ' ', article['description']).strip())\n",
    "        news['content'].append(re.sub(r'(\\r|\\n|<.*?>|… \\[\\+[0-9]+ chars])+', ' ', article['content']).strip())\n",
    "        news['url'].append(article['url'])\n",
    "except:\n",
    "    warnings.warn(\"Fail to get news from NewsAPI Search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.DataFrame(news)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
