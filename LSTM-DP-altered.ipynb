{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f9520ba11fdc1099356e05d27a34ed870b487e4078e45fe1cddd0198c8b5354c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# LSTM model\n",
    "from https://github.com/Xinyi6/DP-LSTM-Differential-Privacy-inspired-LSTM-for-Stock-Prediction-Using-Financial-News and make some changes\n",
    "\n",
    "### Where we can use big compute:\n",
    "- Adding noises to data\n",
    "- The computations of multi-sequence predictions\n",
    "- The calculation of MSE\n",
    "\n",
    "### Where we cannot use big compute:\n",
    "- The training of LSTM\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from numpy import newaxis\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from math import pi,sqrt,exp,pow,log\n",
    "from numpy.linalg import det, inv\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from sklearn import cluster\n",
    "\n",
    "import statsmodels.api as sm \n",
    "import scipy.stats as scs\n",
    "import scipy.optimize as sco\n",
    "import scipy.interpolate as sci\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "# 1. adding noises(?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters setting\n",
    "split = (0.85)  # train_data percent\n",
    "sequence_length=11;  # is the window length of a subset\n",
    "normalise= True  # normalize 3 features\n",
    "batch_size=100;\n",
    "input_dim=3  # ['price','review','sentiment']\n",
    "input_timesteps=10 # the window length of a training data set\n",
    "neurons=50  # number of neurons in one LSTM layer\n",
    "epochs=5\n",
    "prediction_len=1  # predict one day's price\n",
    "dense_output=1  # output size of the last dense layer\n",
    "drop_out=0.1  # dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM MODEL\n",
    "model = Sequential()\n",
    "model.add(LSTM(neurons, input_shape=(input_timesteps, input_dim), return_sequences = True))\n",
    "model.add(Dropout(drop_out))\n",
    "model.add(LSTM(neurons,return_sequences = True))\n",
    "model.add(LSTM(neurons,return_sequences =False))\n",
    "model.add(Dropout(drop_out))\n",
    "model.add(Dense(dense_output, activation='linear'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error',\n",
    "                optimizer='adam')\n",
    "# Fit the model\n",
    "model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi sequence predict\n",
    "data=x_test  # true test data\n",
    "prediction_seqs = []  # prediction data\n",
    "window_size=sequence_length\n",
    "pre_win_num=int(len(data)/prediction_len) # number of predicted windows. Here prediction_len = 1, so the number of predicted windows = the length of test data\n",
    "\n",
    "# !! parallelizable !!\n",
    "for i in range(0,pre_win_num):\n",
    "    curr_frame = data[i*prediction_len]\n",
    "    predicted = []\n",
    "    for j in range(0,prediction_len):\n",
    "      temp=model.predict(curr_frame[newaxis,:,:])[0]\n",
    "      predicted.append(temp)\n",
    "      curr_frame = curr_frame[1:]\n",
    "      curr_frame = np.insert(curr_frame, [window_size-2], predicted[-1], axis=0)\n",
    "    prediction_seqs.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_normalized\n",
    "de_predicted=[]\n",
    "len_pre_win=int(len(data)/prediction_len)\n",
    "len_pre=prediction_len\n",
    "\n",
    "m=0\n",
    "for i in range(0,len_pre_win):\n",
    "    for j in range(0,len_pre):\n",
    "      de_predicted.append(prediction_seqs[i][j][0]*record_max[m]+record_min[m])  # record_max is the max difference among prices, and record_min is the minimum price\n",
    "      m=m+1\n",
    "print(de_predicted)\n",
    "\n",
    "# np.save(../stockdata/result2/sp_5dim_n01_7030.npy',de_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "diff=y_test.shape[0]-prediction_len*pre_win_num\n",
    "\n",
    "for i in range(y_test_ori.shape[0]-diff):\n",
    "    error.append(y_test_ori[i,] - de_predicted[i])\n",
    "    \n",
    "squaredError = []\n",
    "absError = []\n",
    "for val in error:\n",
    "    squaredError.append(val * val) \n",
    "    absError.append(abs(val))\n",
    "\n",
    "error_percent=[]\n",
    "for i in range(len(error)):\n",
    "    val=absError[i]/y_test_ori[i,]\n",
    "    val=abs(val)\n",
    "    error_percent.append(val)\n",
    "\n",
    "mean_error_percent=sum(error_percent) / len(error_percent)\n",
    "accuracy=1-mean_error_percent\n",
    "\n",
    "MSE=sum(squaredError) / len(squaredError)\n",
    "\n",
    "print(\"MSE\",MSE)\n",
    "print('accuracy',accuracy)\n",
    "print('mean_error_percent',mean_error_percent)"
   ]
  }
 ]
}